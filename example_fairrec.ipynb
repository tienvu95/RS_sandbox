{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd12933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip,pickle\n",
    "import numpy as np\n",
    "import random,math,sys\n",
    "import utility\n",
    "import pandas as pd\n",
    "import copy\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5450b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_round_robin(m,n,R,l,T,V,U,F): \n",
    "    # greedy round robin allocation based on a specific ordering of customers (assuming the ordering is done in the relevance scoring matrix before passing it here)\n",
    "    \n",
    "    # creating empty allocations\n",
    "    B={}\n",
    "    for u in U:\n",
    "        B[u]=[]\n",
    "    \n",
    "    # available number of copies of each producer\n",
    "    Z={} # total availability\n",
    "    P=range(n) # set of producers\n",
    "    for p in P:\n",
    "        Z[p]=l\n",
    "    \n",
    "    # allocating the producers to customers\n",
    "    for t in range(1,R+1):\n",
    "        print(\"GRR round number==============================\",t)\n",
    "        for i in range(m):\n",
    "            if T==0:\n",
    "                return B,F\n",
    "            u=U[i]\n",
    "            # choosing the p_ which is available and also in feasible set for the user\n",
    "            possible=[(Z[p]>0)*(p in F[u])*V[u,p] for p in range(n)] \n",
    "            p_=np.argmax(possible) \n",
    "            \n",
    "            if (Z[p_]>0) and (p_ in F[u]) and len(F[u])>0:\n",
    "                B[u].append(p_)\n",
    "                F[u] = list(F[u])\n",
    "                F[u].remove(p_)\n",
    "                Z[p_]=Z[p_]-1\n",
    "                T=T-1\n",
    "            else:\n",
    "                return B,F\n",
    "    # returning the allocation\n",
    "    return B,F;\n",
    "\n",
    "\n",
    "def FairRec(k,V,alpha):\n",
    "    print(\"Start FairRec:\")\n",
    "    m=V.shape[0] # number of customers\n",
    "    n=V.shape[1] # number of producers\n",
    "    \n",
    "    U=range(m) # list of customers\n",
    "    P=range(n) # list of producers\n",
    "\n",
    "    # Allocation set for each customer, initially it is set to empty set\n",
    "    A={}\n",
    "    for u in U:\n",
    "        A[u]=[]\n",
    "\n",
    "    # feasible set for each customer, initially it is set to P\n",
    "    F={}\n",
    "    for u in U:\n",
    "        F[u]=P[:]\n",
    "    #print(sum([len(F[u]) for u in U]))\n",
    "   \n",
    "    # number of copies of each producer\n",
    "    l=int(alpha*m*k/(n+0.0))\n",
    "\n",
    "    # R= number of rounds of allocation to be done in first GRR\n",
    "    R=int(math.ceil((l*n)/(m+0.0)))  \n",
    "\n",
    "    \n",
    "    # total number of copies to be allocated\n",
    "    T= l*n\n",
    "       \n",
    "    # first greedy round-robin allocation\n",
    "    print(\"Start Greedy Round Robin first round:\")\n",
    "    [B,F1]=greedy_round_robin(m,n,R,l,T,V,U[:],F.copy())\n",
    "    F={}\n",
    "    F=F1.copy()\n",
    "    print(\"GRR done\")\n",
    "    # adding the allocation\n",
    "    for u in U:        \n",
    "        A[u]=A[u][:]+B[u][:]\n",
    "    \n",
    "    # second phase\n",
    "    # This phase is different from demo code in paper. Since no limit items for greedy-round-robin, its become this\n",
    "    u_less=[] # customers allocated with <k products till now\n",
    "    for u in A:\n",
    "        if len(A[u])<k:\n",
    "            u_less.append(u)\n",
    "\n",
    "    # allocating every customer till k products\n",
    "    for u in u_less:\n",
    "        scores=V[u,:]\n",
    "        new=scores.argsort()[-(k+k):][::-1]\n",
    "        for p in new:\n",
    "            if p not in A[u]:\n",
    "                A[u].append(p)\n",
    "            if len(A[u])==k:\n",
    "                break\n",
    "\n",
    "    return A;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23379e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance scoring data loaded\n",
      "Start FairRec:\n",
      "Start Greedy Round Robin first round:\n",
      "GRR round number============================== 1\n",
      "GRR round number============================== 2\n",
      "GRR round number============================== 3\n",
      "GRR round number============================== 4\n",
      "GRR round number============================== 5\n",
      "GRR round number============================== 6\n",
      "GRR round number============================== 7\n",
      "GRR round number============================== 8\n",
      "GRR round number============================== 9\n",
      "GRR round number============================== 10\n",
      "GRR round number============================== 11\n",
      "GRR round number============================== 12\n",
      "GRR round number============================== 13\n",
      "GRR round number============================== 14\n",
      "GRR done\n"
     ]
    }
   ],
   "source": [
    "V=np.loadtxt('ml-1m-6.csv',delimiter=',')\n",
    "print(\"relevance scoring data loaded\")\n",
    "\n",
    "# size of recommendation\n",
    "reco_size=int(20)\n",
    "\n",
    "# fraction of MMS to be guaranteed to every producer\n",
    "alpha=float(1)\n",
    "\n",
    "# calling FairRec\n",
    "A=FairRec(reco_size,V,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c42e66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(r'ml1m-6/training_df.pkl')\n",
    "vali_df = pd.read_pickle(r'ml1m-6/testing_df.pkl')   # for validation\n",
    "# vali_df = pickle.load(open('./' + dataname + '/testing_df.pkl'))  # for testing\n",
    "key_genre = pd.read_pickle(r'ml1m-6/key_genre.pkl')\n",
    "item_idd_genre_list = pd.read_pickle(r'ml1m-6/item_idd_genre_list.pkl')\n",
    "genre_item_vector = pd.read_pickle(r'ml1m-6/genre_item_vector.pkl')\n",
    "genre_count = pd.read_pickle(r'ml1m-6/genre_count.pkl')\n",
    "user_genre_count = pd.read_pickle(r'ml1m-6/user_genre_count.pkl')\n",
    "\n",
    "num_item = len(train_df['item_id'].unique())\n",
    "num_user = len(train_df['user_id'].unique())\n",
    "num_genre = len(key_genre)\n",
    "top1 = 1\n",
    "top2 = 5\n",
    "top3 = 10\n",
    "top4 = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91f4ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre_list = []\n",
    "for u in range(num_item):\n",
    "    gl = item_idd_genre_list[u]\n",
    "    tmp = []\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            tmp.append(g)\n",
    "    item_genre_list.append(tmp)\n",
    "\n",
    "item_genre = np.zeros((num_item, num_genre))\n",
    "for i in range(num_item):\n",
    "    gl = item_genre_list[i]\n",
    "    for k in range(num_genre):\n",
    "        if key_genre[k] in gl:\n",
    "            item_genre[i, k] = 1.0\n",
    "\n",
    "genre_count_mean_reciprocal = []\n",
    "\n",
    "##there are six key_genre --> in the training dataset, count the number of movies for each genre\n",
    "#genre_count = dictionary with number of movies for each keygrenre\n",
    "for k in key_genre:\n",
    "    genre_count_mean_reciprocal.append(1.0 / genre_count[k])\n",
    "genre_count_mean_reciprocal = (np.array(genre_count_mean_reciprocal)).reshape((num_genre, 1))\n",
    "genre_error_weight = np.dot(item_genre, genre_count_mean_reciprocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57a7f5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.777458 ,  4.221402 ,  5.198299 , ..., -4.2804947, -2.578201 ,\n",
       "        -2.816697 ],\n",
       "       [-0.811322 ,  1.6305199,  1.3584685, ..., -1.1151903, -3.3449132,\n",
       "        -4.613763 ],\n",
       "       [ 2.7363856,  1.0603654,  5.1922445, ..., -3.727843 , -3.6910203,\n",
       "        -3.445971 ],\n",
       "       ...,\n",
       "       [ 0.3022063,  2.698015 ,  1.7298616, ..., -1.4951588, -1.1846492,\n",
       "        -1.3607007],\n",
       "       [ 3.5729375,  6.708638 ,  4.714961 , ..., -4.493719 , -2.7313833,\n",
       "        -2.9217112],\n",
       "       [ 1.204689 ,  2.7632651,  1.7827291, ..., -3.1170988, -1.994886 ,\n",
       "        -3.3972826]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_tensor = (np.load('Q_tensor.npy'))\n",
    "P_tensor = (np.load('P_tensor.npy'))\n",
    "Rec = np.matmul(P_tensor, (Q_tensor).T)\n",
    "Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1393e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec = copy.copy(Rec)\n",
    "\n",
    "count1_dict = dict()\n",
    "count5_dict = dict()\n",
    "count10_dict = dict()\n",
    "count15_dict = dict()\n",
    "test_count = dict()\n",
    "recall1_dict = dict()\n",
    "recall5_dict = dict()\n",
    "recall10_dict = dict()\n",
    "recall15_dict = dict()\n",
    "user_count_dict = dict()\n",
    "num_user = Rec.shape[0]\n",
    "num_item = Rec.shape[1]\n",
    "top1_dict = dict()\n",
    "top5_dict = dict()\n",
    "top10_dict = dict()\n",
    "top15_dict = dict()\n",
    "avg_top1_dict = dict()\n",
    "avg_top5_dict = dict()\n",
    "avg_top10_dict = dict()\n",
    "avg_top15_dict = dict()\n",
    "tmp_top1_dict = dict()\n",
    "tmp_top5_dict = dict()\n",
    "tmp_top10_dict = dict()\n",
    "tmp_top15_dict = dict()\n",
    "genre_rank_count = dict()\n",
    "rank_count = np.ones(num_item) * 1e-10\n",
    "\n",
    "genre_to_be_rank = dict()\n",
    "\n",
    "for k in key_genre:\n",
    "    genre_rank_count[k] = np.zeros(num_item)\n",
    "    top1_dict[k] = 0.0\n",
    "    top5_dict[k] = 0.0\n",
    "    top10_dict[k] = 0.0\n",
    "    top15_dict[k] = 0.0\n",
    "    avg_top1_dict[k] = 0.0\n",
    "    avg_top5_dict[k] = 0.0\n",
    "    avg_top10_dict[k] = 0.0\n",
    "    avg_top15_dict[k] = 0.0\n",
    "    tmp_top1_dict[k] = 0.0\n",
    "    tmp_top5_dict[k] = 0.0\n",
    "    tmp_top10_dict[k] = 0.0\n",
    "    tmp_top15_dict[k] = 0.0\n",
    "\n",
    "    recall1_dict[k] = 0.0\n",
    "    recall5_dict[k] = 0.0\n",
    "    recall10_dict[k] = 0.0\n",
    "    recall15_dict[k] = 0.0\n",
    "    user_count_dict[k] = 0.0\n",
    "    count1_dict[k] = 0.0\n",
    "    count5_dict[k] = 0.0\n",
    "    count10_dict[k] = 0.0\n",
    "    count15_dict[k] = 0.0\n",
    "    genre_to_be_rank[k] = 0.0\n",
    "    test_count[k] = 0.0\n",
    "\n",
    "for u in range(num_user):\n",
    "    like_item = (train_df.loc[train_df['user_id'] == u, 'item_id']).tolist()\n",
    "    Rec[u, like_item] = -100000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fb53499",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in A.keys():  # iterate each user\n",
    "    u_test = (vali_df.loc[vali_df['user_id'] == u, 'item_id']).tolist()\n",
    "    u_pred = Rec[u, :]\n",
    "\n",
    "    top15_item_idx_no_train = A[i][:-5]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # calculate the recall for different genres\n",
    "    if not len(u_test) == 0:\n",
    "        recall_1_tmp_dict, recall_5_tmp_dict, recall_10_tmp_dict, recall_15_tmp_dict, \\\n",
    "        count_1_tmp_dict, count_5_tmp_dict, count_10_tmp_dict, count_15_tmp_dict, test_tmp_dict\\\n",
    "            = utility.user_recall(top15, u_test, item_genre_list, key_genre)\n",
    "        for k in key_genre:\n",
    "            count1_dict[k] += count_1_tmp_dict[k]\n",
    "            count5_dict[k] += count_5_tmp_dict[k]\n",
    "            count10_dict[k] += count_10_tmp_dict[k]\n",
    "            count15_dict[k] += count_15_tmp_dict[k]\n",
    "            test_count[k] += test_tmp_dict[k]\n",
    "            if recall_1_tmp_dict[k] == -1:\n",
    "                continue\n",
    "            recall1_dict[k] += recall_1_tmp_dict[k]\n",
    "            recall5_dict[k] += recall_5_tmp_dict[k]\n",
    "            recall10_dict[k] += recall_10_tmp_dict[k]\n",
    "            recall15_dict[k] += recall_15_tmp_dict[k]\n",
    "            user_count_dict[k] += 1.0\n",
    "\n",
    "    # calculate ranking probability\n",
    "    rank = 1\n",
    "    for r in top15:\n",
    "        gl = item_idd_genre_list[int(r[0])]\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                genre_rank_count[g][rank - 1] += 1.0\n",
    "                rank_count[rank - 1] += 1.0\n",
    "                if rank <= top4:\n",
    "                    tmp_top15_dict[g] += 1.0\n",
    "                    if rank <= top3:\n",
    "                        tmp_top10_dict[g] += 1.0\n",
    "                        if rank <= top2:\n",
    "                            tmp_top5_dict[g] += 1.0\n",
    "                            if rank <= top1:\n",
    "                                tmp_top1_dict[g] += 1.0\n",
    "        rank += 1\n",
    "    for k in key_genre:\n",
    "        top1_dict[k] += tmp_top1_dict[k]\n",
    "        top5_dict[k] += tmp_top5_dict[k]\n",
    "        top10_dict[k] += tmp_top10_dict[k]\n",
    "        top15_dict[k] += tmp_top15_dict[k]\n",
    "        avg_top1_dict[k] += (1.0 * tmp_top1_dict[k] / user_genre_count[u][k])\n",
    "        avg_top5_dict[k] += (1.0 * tmp_top5_dict[k] / user_genre_count[u][k])\n",
    "        avg_top10_dict[k] += (1.0 * tmp_top10_dict[k] / user_genre_count[u][k])\n",
    "        avg_top15_dict[k] += (1.0 * tmp_top15_dict[k] / user_genre_count[u][k])\n",
    "        tmp_top1_dict[k] = 0.0\n",
    "        tmp_top5_dict[k] = 0.0\n",
    "        tmp_top10_dict[k] = 0.0\n",
    "        tmp_top15_dict[k] = 0.0\n",
    "        genre_to_be_rank[k] += user_genre_count[u][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4eb7704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_std(dictionary):\n",
    "    tmp = []\n",
    "    for key, value in sorted(dictionary.items(), key = lambda x: x[0]):\n",
    "        tmp.append(value)\n",
    "    rstd = np.std(tmp) / (np.mean(tmp) + 1e-10)\n",
    "    return rstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27979660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "# System-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.01052\t\t0.02477\t\t0.02778\t\t0.02781\n",
      "# Horror\t\t0.00977\t\t0.01822\t\t0.01972\t\t0.01972\n",
      "# Crime\t\t0.01359\t\t0.02005\t\t0.02005\t\t0.02005\n",
      "# Adventure\t\t0.01549\t\t0.03392\t\t0.03487\t\t0.03487\n",
      "# Children's\t\t0.01077\t\t0.02038\t\t0.02046\t\t0.02046\n",
      "# Romance\t\t0.00736\t\t0.01399\t\t0.01512\t\t0.01512\n",
      "# relative std\t\t0.23378\t\t0.28570\t\t0.28168\t\t0.28177\n",
      "####################################################################################################\n",
      "# User-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.01052\t\t0.02477\t\t0.02778\t\t0.02781\n",
      "# Horror\t\t0.00977\t\t0.01822\t\t0.01972\t\t0.01972\n",
      "# Crime\t\t0.01359\t\t0.02005\t\t0.02005\t\t0.02005\n",
      "# Adventure\t\t0.01549\t\t0.03392\t\t0.03487\t\t0.03487\n",
      "# Children's\t\t0.01077\t\t0.02038\t\t0.02046\t\t0.02046\n",
      "# Romance\t\t0.00736\t\t0.01399\t\t0.01512\t\t0.01512\n",
      "# relative std\t\t0.23378\t\t0.28570\t\t0.28168\t\t0.28177\n",
      "####################################################################################################\n",
      "# System-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00142\t\t0.00556\t\t0.00988\t\t0.01444\n",
      "# Horror\t\t0.00039\t\t0.00254\t\t0.00527\t\t0.00759\n",
      "# Crime\t\t0.00075\t\t0.00398\t\t0.00778\t\t0.01217\n",
      "# Adventure\t\t0.00108\t\t0.00473\t\t0.00855\t\t0.01244\n",
      "# Children's\t\t0.00041\t\t0.00248\t\t0.00617\t\t0.00999\n",
      "# Romance\t\t0.00072\t\t0.00381\t\t0.00749\t\t0.01102\n",
      "# relative std\t\t0.45536\t\t0.28696\t\t0.20004\t\t0.18969\n",
      "####################################################################################################\n",
      "# User-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00142\t\t0.00556\t\t0.00988\t\t0.01444\n",
      "# Horror\t\t0.00039\t\t0.00254\t\t0.00527\t\t0.00759\n",
      "# Crime\t\t0.00075\t\t0.00398\t\t0.00778\t\t0.01217\n",
      "# Adventure\t\t0.00108\t\t0.00473\t\t0.00855\t\t0.01244\n",
      "# Children's\t\t0.00041\t\t0.00248\t\t0.00617\t\t0.00999\n",
      "# Romance\t\t0.00072\t\t0.00381\t\t0.00749\t\t0.01102\n",
      "# relative std\t\t0.45536\t\t0.28696\t\t0.20004\t\t0.18969\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "for k in key_genre:\n",
    "    count1_dict[k] /= test_count[k]\n",
    "    count5_dict[k] /= test_count[k]\n",
    "    count10_dict[k] /= test_count[k]\n",
    "    count15_dict[k] /= test_count[k]\n",
    "    recall1_dict[k] /= user_count_dict[k]\n",
    "    recall5_dict[k] /= user_count_dict[k]\n",
    "    recall10_dict[k] /= user_count_dict[k]\n",
    "    recall15_dict[k] /= user_count_dict[k]\n",
    "print('')\n",
    "print('#' * 100)\n",
    "print('# System-level Recall:')\n",
    "print('# \\t\\t\\tRecall@%d\\tRecall@%d\\tRecall@%d\\tRecall@%d' % (top1, top2, top3, top4))\n",
    "for k in key_genre:\n",
    "    print('# ' + k + '\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (count1_dict[k], count5_dict[k], count10_dict[k], count15_dict[k]))\n",
    "recall1_std = relative_std(count1_dict)\n",
    "recall5_std = relative_std(count5_dict)\n",
    "recall10_std = relative_std(count10_dict)\n",
    "recall15_std = relative_std(count15_dict)\n",
    "print('# relative std\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (recall1_std, recall5_std, recall10_std, recall15_std))\n",
    "print('#' * 100)\n",
    "\n",
    "print('# User-level Recall:')\n",
    "print('# \\t\\t\\tRecall@%d\\tRecall@%d\\tRecall@%d\\tRecall@%d' % (top1, top2, top3, top4))\n",
    "for k in key_genre:\n",
    "    print('# ' + k + '\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (\n",
    "        recall1_dict[k], recall5_dict[k], recall10_dict[k], recall15_dict[k]))\n",
    "recall1_std_user = relative_std(recall1_dict)\n",
    "recall5_std_user = relative_std(recall5_dict)\n",
    "recall10_std_user = relative_std(recall10_dict)\n",
    "recall15_std_user = relative_std(recall15_dict)\n",
    "print('# relative std\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (recall1_std_user, recall5_std_user, recall10_std_user, recall15_std_user))\n",
    "print('#' * 100)\n",
    "\n",
    "# calculate the average genre ranking probability across users, and calculate system-level ranking probability\n",
    "for k in key_genre:\n",
    "    avg_top1_dict[k] /= num_user\n",
    "    avg_top5_dict[k] /= num_user\n",
    "    avg_top10_dict[k] /= num_user\n",
    "    avg_top15_dict[k] /= num_user\n",
    "\n",
    "    top1_dict[k] /= genre_to_be_rank[k]\n",
    "    top5_dict[k] /= genre_to_be_rank[k]\n",
    "    top10_dict[k] /= genre_to_be_rank[k]\n",
    "    top15_dict[k] /= genre_to_be_rank[k]\n",
    "\n",
    "print('# System-level top ranking probability:')\n",
    "print('# \\t\\t\\t@%d\\t\\t@%d\\t\\t@%d\\t\\t@%d' % (top1, top2, top3, top4))\n",
    "for k in key_genre:\n",
    "    print('# ' + k + '\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (top1_dict[k], top5_dict[k], top10_dict[k], top15_dict[k]))\n",
    "top1_std = relative_std(top1_dict)\n",
    "top5_std = relative_std(top5_dict)\n",
    "top10_std = relative_std(top10_dict)\n",
    "top15_std = relative_std(top15_dict)\n",
    "print('# relative std\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (top1_std, top5_std, top10_std, top15_std))\n",
    "print('#' * 100)\n",
    "\n",
    "print('# User-level top ranking probability:')\n",
    "print('# \\t\\t\\t@%d\\t\\t@%d\\t\\t@%d\\t\\t@%d' % (top1, top2, top3, top4))\n",
    "for k in key_genre:\n",
    "    print('# ' + k + '\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (avg_top1_dict[k], avg_top5_dict[k], avg_top10_dict[k], avg_top15_dict[k]))\n",
    "top1_std_user = relative_std(avg_top1_dict)\n",
    "top5_std_user = relative_std(avg_top5_dict)\n",
    "top10_std_user = relative_std(avg_top10_dict)\n",
    "top15_std_user = relative_std(avg_top15_dict)\n",
    "print('# relative std\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f\\t\\t%.5f' % (top1_std_user, top5_std_user, top10_std_user, top15_std_user))\n",
    "print('#' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420daf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
